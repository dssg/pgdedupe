# Schema for Dedupe's tables:
schema: dedupe
# The source table to dedupe:
table: entries
# The column in the source table that is the key
key: entry_id
# The fields to use as evidence of a duplicate row and their comparison operator:
fields:
    -   field: ssn
        type: String
        has missing: true
    -   field: first_name
        type: String
    -   field: last_name
        type: String
    -   field: dob
        type: String
        # has missing: true
    -   field: race
        type: Categorical
        categories: [pacisland, amindian, asian, other, black, white]
    -   field: ethnicity
        type: Categorical
        categories: [hispanic, nonhispanic]
    -   field: sex
        type: Categorical
        categories: [M, F]
interactions:
    - [last_name, dob]
    - [ssn, dob]
# This filter allows you to specify a bare minimum set of required columns
filter_condition: last_name is not null AND (ssn is not null OR (first_name is not null AND dob is not null))
# And after dedupe, we can do an exact record linkage merge of the found clusters
merge_exact:
    - [first_name, last_name, dob]
    - [last_name, ssn]
# Turn off interactive labelling; this requires a saved training set
prompt_for_labels: False
# Specify the location of the saved training dataset
training_file: tests/dedup_postgres_training.json
